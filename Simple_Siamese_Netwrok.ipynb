{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkArrlTRl8WgKEZmUxY3W0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahamsi/github-upload/blob/main/Simple_Siamese_Netwrok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGCQyTdPAm41"
      },
      "outputs": [],
      "source": [
        "#This architecture uses a binary classification loss with no transfer learning.\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from imutils import build_montages\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs(images, labels):\n",
        "    # initialize two empty lists to hold the (image, image) pairs and\n",
        "    # labels to indicate if a pair is positive or negative\n",
        "    pairImages = []\n",
        "    pairLabels = []\n",
        "    # calculate the total number of classes present in the dataset\n",
        "    # and then build a list of indexes for each class label that\n",
        "    # provides the indexes for all examples with a given label\n",
        "    numClasses = len(np.unique(labels))\n",
        "    idx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
        "    # loop over all images\n",
        "    for idxA in range(len(images)):\n",
        "        # grab the current image and label belonging to the current\n",
        "        # iteration\n",
        "        currentImage = images[idxA]\n",
        "        label = labels[idxA]\n",
        "        # randomly pick an image that belongs to the *same* class\n",
        "        # label\n",
        "        idxB = np.random.choice(idx[label])\n",
        "        posImage = images[idxB]\n",
        "        # prepare a positive pair and update the images and labels\n",
        "        # lists, respectively\n",
        "        pairImages.append([currentImage, posImage])\n",
        "        pairLabels.append([1])\n",
        "        # grab the indices for each of the class labels *not* equal to\n",
        "        # the current label and randomly pick an image corresponding\n",
        "        # to a label *not* equal to the current label\n",
        "        negIdx = np.where(labels != label)[0]\n",
        "        negImage = images[np.random.choice(negIdx)]\n",
        "        # prepare a negative pair of images and update our lists\n",
        "        pairImages.append([currentImage, negImage])\n",
        "        pairLabels.append([0])\n",
        "    # return a 2-tuple of our image pairs and labels\n",
        "    return (np.array(pairImages), np.array(pairLabels))"
      ],
      "metadata": {
        "id": "ggVKTnINBRMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load MNIST dataset and scale the pixel values to the range of [0, 1]\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "# build the positive and negative image pairs\n",
        "print(\"[INFO] preparing positive and negative pairs...\")\n",
        "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
        "(pairTest, labelTest) = make_pairs(testX, testY)\n",
        "# initialize the list of images that will be used when building our\n",
        "# montage\n",
        "images = []"
      ],
      "metadata": {
        "id": "6ntA397tBZG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over a sample of our training pairs\n",
        "for i in np.random.choice(np.arange(0, len(pairTrain)), size=(49,)):\n",
        "    # grab the current image pair and label\n",
        "    imageA = pairTrain[i][0]\n",
        "    imageB = pairTrain[i][1]\n",
        "    label = labelTrain[i]\n",
        "    # to make it easier to visualize the pairs and their positive or\n",
        "    # negative annotations, we're going to \"pad\" the pair with four\n",
        "    # pixels along the top, bottom, and right borders, respectively\n",
        "    output = np.zeros((36, 60), dtype=\"uint8\")\n",
        "    pair = np.hstack([imageA, imageB])\n",
        "    output[4:32, 0:56] = pair\n",
        "    # set the text label for the pair along with what color we are\n",
        "    # going to draw the pair in (green for a \"positive\" pair and\n",
        "    # red for a \"negative\" pair)\n",
        "    text = \"neg\" if label[0] == 0 else \"pos\"\n",
        "    color = (0, 0, 255) if label[0] == 0 else (0, 255, 0)\n",
        "    # create a 3-channel RGB image from the grayscale pair, resize\n",
        "    # it from 60x36 to 96x51 (so we can better see it), and then\n",
        "    # draw what type of pair it is on the image\n",
        "    vis = cv2.merge([output] * 3)\n",
        "    vis = cv2.resize(vis, (96, 51), interpolation=cv2.INTER_LINEAR)\n",
        "    cv2.putText(vis, text, (2, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "    color, 2)\n",
        "    # add the pair visualization to our list of output images\n",
        "    images.append(vis)\n",
        "    # construct the montage for the images\n",
        "#montage = build_montages(images, (96, 51), (7, 7))[0]\n",
        "# show the output montage\n",
        "#cv2.imshow(\"Siamese Image Pairs\", montage)\n",
        "#cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "iX0_V8l1BhnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configuration\n",
        "# import the necessary packages\n",
        "import os\n",
        "# specify the shape of the inputs for our network\n",
        "IMG_SHAPE = (28, 28, 1)\n",
        "# specify the batch size and number of epochs\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "DPycQfGBB2RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the path to the base output directory\n",
        "BASE_OUTPUT = \"output\"\n",
        "# use the base output path to derive the path to the serialized\n",
        "# model along with training history plot\n",
        "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"siamese_model\"])\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])"
      ],
      "metadata": {
        "id": "s2ZZt0nfB6uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D"
      ],
      "metadata": {
        "id": "gutOfzv5B9zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_siamese_model(inputShape, embeddingDim=48):\n",
        "    # specify the inputs for the feature extractor network\n",
        "    inputs = Input(inputShape)\n",
        "    # define the first set of CONV => RELU => POOL => DROPOUT layers\n",
        "    x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    # second set of CONV => RELU => POOL => DROPOUT layers\n",
        "    x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    # prepare the final outputs\n",
        "    pooledOutput = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(embeddingDim)(pooledOutput)\n",
        "    # build the model\n",
        "    model = Model(inputs, outputs)\n",
        "    # return the model to the calling function\n",
        "    return model"
      ],
      "metadata": {
        "id": "AUQvEzmiCC3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CQyzSm9lCHaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vectors):\n",
        "    # unpack the vectors into separate lists\n",
        "    (featsA, featsB) = vectors\n",
        "    \n",
        "    # compute the sum of squared distances between the vectors\n",
        "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
        "        keepdims=True)\n",
        "    # return the euclidean distance between the vectors\n",
        "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ],
      "metadata": {
        "id": "E6O5LvD8CKpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training(H, plotPath):\n",
        "    # construct a plot that plots and saves the training history\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.savefig(plotPath)"
      ],
      "metadata": {
        "id": "DMMOhgDLCPXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "# add a channel dimension to the images\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "# prepare the positive and negative pairs\n",
        "print(\"[INFO] preparing positive and negative pairs...\")\n",
        "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
        "(pairTest, labelTest) = make_pairs(testX, testY)"
      ],
      "metadata": {
        "id": "ZxQiJ4eWCTRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure the siamese network\n",
        "print(\"[INFO] building siamese network...\")\n",
        "imgA = Input(shape=IMG_SHAPE)\n",
        "imgB = Input(shape=IMG_SHAPE)\n",
        "featureExtractor = build_siamese_model(IMG_SHAPE)\n",
        "featsA = featureExtractor(imgA)\n",
        "featsB = featureExtractor(imgB)"
      ],
      "metadata": {
        "id": "HtLW0eflCd1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, construct the siamese network\n",
        "from tensorflow.keras.layers import Lambda\n",
        "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
        "outputs = Dense(10, activation=\"relu\")(distance)\n",
        "outputs = Dense(1, activation=\"sigmoid\")(outputs)\n",
        "model = Model(inputs=[imgA, imgB], outputs=outputs)"
      ],
      "metadata": {
        "id": "3d1NzYXjCjrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "history = model.fit(\n",
        "    [pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
        "    validation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "nYGwwC1HCps5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving siamese model...\")\n",
        "model.save(MODEL_PATH)\n",
        "# plot the training history\n",
        "print(\"[INFO] plotting training history...\")\n",
        "plot_training(history, PLOT_PATH)"
      ],
      "metadata": {
        "id": "_ohAs9HIDhKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairTrain.shape"
      ],
      "metadata": {
        "id": "onk-vuscDoTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (i, (imageA, imageB)) in enumerate(pairTest):\n",
        "    imageA = np.expand_dims(imageA, axis=0)\n",
        "    imageB = np.expand_dims(imageB, axis=0)\n",
        "    print(imageB.shape)\n",
        "    preds = model.predict([imageA, imageB])\n",
        "    proba = preds[0][0]\n",
        "    print(proba, labelTest[i])"
      ],
      "metadata": {
        "id": "M74yVsmpDse4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = model.predict([pairTest[:, 0], pairTest[:, 1]])\n",
        "y_pred=y_pred<=0.00001\n",
        "accuracy_score(labelTest, y_pred)"
      ],
      "metadata": {
        "id": "XHpj7lA3EEd9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}